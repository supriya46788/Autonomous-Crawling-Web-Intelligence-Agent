{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "_70lQyTGHIrk"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests beautifulsoup4 google-generativeai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n"
      ],
      "metadata": {
        "id": "EF5f3T4xK5iR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "def fetch_page(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=15)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
        "            tag.decompose()\n",
        "\n",
        "        text = soup.get_text(separator=\" \")\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        return soup, text\n",
        "    except:\n",
        "        return None, \"\"\n"
      ],
      "metadata": {
        "id": "f6KnUBAxLofq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_internal_links(soup, base_url):\n",
        "    links = set()\n",
        "    base_domain = urlparse(base_url).netloc\n",
        "\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = urljoin(base_url, a[\"href\"])\n",
        "        if urlparse(href).netloc == base_domain:\n",
        "            links.add(href.split(\"#\")[0])\n",
        "\n",
        "    return list(links)\n"
      ],
      "metadata": {
        "id": "_DEX0RFSLw59"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def planner_agent(question):\n",
        "    prompt = f\"\"\"\n",
        "You are a planning agent.\n",
        "\n",
        "Goal: Answer the question using website evidence.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Create a step-by-step plan for how a web agent should navigate and verify.\n",
        "Only output steps. Do not answer.\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text\n"
      ],
      "metadata": {
        "id": "RIxBpoZBLzQM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evidence_agent(content, question):\n",
        "    prompt = f\"\"\"\n",
        "You are an evidence-checking agent.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Website content:\n",
        "\\\"\\\"\\\"\n",
        "{content[:3000]}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Does this content contain strong evidence to answer the question?\n",
        "\n",
        "Reply EXACTLY in this format:\n",
        "RESULT: YES or NO\n",
        "REASON: one short line\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text\n"
      ],
      "metadata": {
        "id": "oPH470YVL1iK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_agent(evidence, question):\n",
        "    prompt = f\"\"\"\n",
        "You are a reasoning agent.\n",
        "\n",
        "Answer the question using ONLY the evidence below.\n",
        "If evidence is insufficient, say NOT FOUND.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Evidence:\n",
        "\\\"\\\"\\\"\n",
        "{evidence}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text\n"
      ],
      "metadata": {
        "id": "AA7oTXrDL5aO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crawling_web_agent(start_url, question, max_pages=6):\n",
        "    visited = set()\n",
        "    to_visit = [start_url]\n",
        "    evidence_memory = []\n",
        "\n",
        "    print(\"ðŸ¤– AGENT ACTIVATED\")\n",
        "    print(\"ðŸŽ¯ GOAL:\", question)\n",
        "\n",
        "    print(\"\\nðŸ§  PLANNING...\")\n",
        "    print(planner_agent(question))\n",
        "\n",
        "    while to_visit and len(visited) < max_pages:\n",
        "        current_url = to_visit.pop(0)\n",
        "\n",
        "        if current_url in visited:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nðŸŒ VISITING PAGE: {current_url}\")\n",
        "        visited.add(current_url)\n",
        "\n",
        "        soup, text = fetch_page(current_url)\n",
        "        if not soup:\n",
        "            print(\"âš ï¸ Failed to read page, skipping\")\n",
        "            continue\n",
        "\n",
        "        print(\"ðŸ” ANALYZING CONTENT...\")\n",
        "        evaluation = evidence_agent(text, question)\n",
        "        print(evaluation)\n",
        "\n",
        "        if \"RESULT: YES\" in evaluation:\n",
        "            print(\"âœ… EVIDENCE FOUND!\")\n",
        "            evidence_memory.append(text)\n",
        "            break\n",
        "        else:\n",
        "            print(\"âŒ Not found here. Deciding next action...\")\n",
        "\n",
        "        print(\"ðŸ”— DISCOVERING NEW LINKS...\")\n",
        "        links = extract_internal_links(soup, current_url)\n",
        "\n",
        "        for link in links:\n",
        "            if link not in visited and link not in to_visit:\n",
        "                to_visit.append(link)\n",
        "\n",
        "        print(f\"ðŸ“Œ Pages queued: {len(to_visit)}\")\n",
        "\n",
        "    print(\"\\nðŸ§  FINAL DECISION...\")\n",
        "    if evidence_memory:\n",
        "        return decision_agent(\"\\n\".join(evidence_memory), question)\n",
        "    else:\n",
        "        return \"NOT FOUND: The agent explored the website but could not verify the answer.\"\n"
      ],
      "metadata": {
        "id": "WrkAhu3zL8EM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.geeksforgeeks.org/\"\n",
        "question = \"Does this website provide machine learning courses? if yes then provide the exact link\"\n",
        "\n",
        "answer = crawling_web_agent(url, question)\n",
        "print(\"\\nðŸŸ¢ FINAL ANSWER:\\n\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "r95nnNp8L-dY",
        "outputId": "83cec20a-69ce-4e2b-f185-85dea24d44ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¤– AGENT ACTIVATED\n",
            "ðŸŽ¯ GOAL: Does this website provide machine learning courses? if yes then provide the exact link\n",
            "\n",
            "ðŸ§  PLANNING...\n",
            "1.  Navigate to the website's homepage.\n",
            "2.  Scan the main navigation menu (header, sidebar) and footer for links commonly associated with educational offerings, such as \"Courses,\" \"Programs,\" \"Academics,\" \"Learning,\" \"Degrees,\" \"Certifications,\" \"Training,\" \"Study,\" or \"Curriculum.\"\n",
            "3.  If a promising navigation link is found, click on it. On the subsequent page(s), search for keywords like \"machine learning,\" \"ML,\" \"artificial intelligence,\" \"AI,\" \"deep learning,\" \"neural networks,\" or \"data science.\"\n",
            "4.  If no obvious navigation links are found or the search on those pages yields no results, locate the website's search bar (if available).\n",
            "5.  Use the search bar with queries such as \"machine learning courses,\" \"ML courses,\" \"artificial intelligence courses,\" \"AI training,\" or \"data science programs.\"\n",
            "6.  Examine the search results. If any results appear relevant, click on the link(s) to navigate to the respective page(s).\n",
            "7.  On any page identified as potentially offering machine learning courses, verify the content to confirm it explicitly provides courses or programs in machine learning.\n",
            "8.  If machine learning courses are confirmed, extract and provide the exact URL of the page detailing these courses.\n",
            "\n",
            "ðŸŒ VISITING PAGE: https://www.geeksforgeeks.org/\n",
            "ðŸ” ANALYZING CONTENT...\n",
            "RESULT: NO\n",
            "REASON: The content confirms the provision of machine learning courses but does not provide an exact link to them.\n",
            "âŒ Not found here. Deciding next action...\n",
            "ðŸ”— DISCOVERING NEW LINKS...\n",
            "ðŸ“Œ Pages queued: 70\n",
            "\n",
            "ðŸŒ VISITING PAGE: https://www.geeksforgeeks.org/courses/category/development-testing\n",
            "ðŸ” ANALYZING CONTENT...\n",
            "RESULT: YES\n",
            "REASON: The content explicitly lists \"ML and Data Science\" under both \"COURSE TYPE\" and \"Courses\".\n",
            "âœ… EVIDENCE FOUND!\n",
            "\n",
            "ðŸ§  FINAL DECISION...\n",
            "\n",
            "ðŸŸ¢ FINAL ANSWER:\n",
            " Yes, this website provides machine learning courses.\n",
            "\n",
            "NOT FOUND (The evidence does not provide the exact link for machine learning courses.)\n"
          ]
        }
      ]
    }
  ]
}